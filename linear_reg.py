# -*- coding: utf-8 -*-
"""linear_reg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xDRGxjw4GglranrG3YUo85X85b_7JOOj

https://scikit-learn.org/stable/modules/linear_model.html#perceptron
**LinearRegression** fits a linear model with coefficients to minimize the residual sum of squares(leasted squares) between the observed targets in the dataset, and the targets predicted by the linear approximation. 

***The coefficient estimates for Ordinary Least Squares rely on the independence of the features. ***
"""

from sklearn import linear_model
import matplotlib.pyplot as plt
import numpy as np
import random
from sklearn.metrics import r2_score

#data creation
noise=np.zeros(20)
for i in range(1,21):
  noise[i-1]=random.random()
X=np.arange(-10,10)
Y=3*X+4+noise*2

#model fitting
model = linear_model.LinearRegression()#create a linear regression model
#call .reshape() on x b/c this array is required to be two-dimensional
model.fit(X.reshape((-1,1)),Y)#fit it using the existing data.
print("coefficient:",model.coef_)
print("y intercept:",model.intercept_)
print('coefficient of determination:', model.score(X.reshape((-1,1)),Y))#r^2

Y_pred = model.predict(X.reshape((-1,1)))
Yp=np.reshape(Y_pred,-1)#Use numpy.reshape(array, newshape) with -1 as newshape to reshape array into a vector.
#plot the data
plt.plot(X,Y,label="real data")
plt.plot(X,Yp,label="predicted data")
plt.xlabel("x")
plt.ylabel("y")
plt.legend()
plt.show()